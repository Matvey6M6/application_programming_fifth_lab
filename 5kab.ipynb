{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kingtuler1454/torch/blob/main/5kab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP67NcnxYIcy"
      },
      "source": [
        "1.   Необходимо загрузить исходный набор данных и соответствующие метки классов.\n",
        "2.   Произвести разделение загруженного набора данных на обучающую, тестовую и валидационую выборки (в соотношении 80:10:10). Проверить, что сформированные выборки сбалансированы.\n",
        "3.   Написать модель нейронной сети для решения задачи классификации.\n",
        "4.   Описать пайплайн предобработки данных. **ВАЖНО**: что так как ваш вариант предполагает работу с текстом, то необходимо выполниить векторизацию данных (подробности в туториале).\n",
        "4.   Написать `train loop` (цикл обучения). Провести эксперименты по обучению с различными значениями параметров `learning rate` (скорость обучения) и `ba\n",
        "tch size` (размер мини-пакета). Выбрать по 3 значения для `learning rate` и `batch size` (итоговое количество экспериментов будет 9).\n",
        "5.   Для каждого проведенного эксперимента вывести графики для значения функции потерь (ось `x` - итерация обучения/номер эпохи; ось `y` - значение функции потерь) и выбранной метрики качества (ось `x` - итерация обучения/номер эпохи; ось `y` - значение метрики качества). Графики необходимо выводить как для обучающей, так и для валидационной выборки.\n",
        "6.   Оценить качество работы модели на тестовой выборке.\n",
        "7.   Сделайте выводы по полученным результатам проведенных экспериментов. Какую модель из всех полученных стоит использовать?\n",
        "8.   Сохранить обученную модель.\n",
        "9.   Выполните повторную инициализацию модели и загрузку весов.  Продемонстрируйте работоспособность модели (пропустите через нее какой-то отзыв/рецензию и выведите результат).\n",
        "\n",
        "\n",
        "https://www.kaggle.com/code/shivammehta007/spam-not-spam-classifier-with-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHRjiS4lXzLq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from numpy import loadtxt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import os\n",
        "from tqdm import trange\n",
        "\n",
        "from pymystem3 import Mystem\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import PorterStemmer\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Lemmatize(src: list):\n",
        "    ''' Лемматизирует переданный датасет\n",
        "    '''\n",
        "    text_nomalized = ' '.join(src).lower() \n",
        "\n",
        "    m = Mystem()\n",
        "    lemmas = m.lemmatize(text_nomalized)\n",
        "    \n",
        "    return lemmas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWXZpyxPlkB-"
      },
      "source": [
        "Описать пайплайн предобработки данных. ВАЖНО: что так как ваш вариант предполагает работу с текстом, то необходимо выполниить векторизацию данных (подробности в туториале).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"dataframe.csv\")\n",
        "\n",
        "data.dropna(inplace=True)\n",
        "remove_non_alphabets = lambda x: re.sub(r'[^а-яА-Я]',' ',str(x))\n",
        "\n",
        "tokenize = lambda x: word_tokenize(x, language = \"russian\")\n",
        "\n",
        "ps = PorterStemmer()\n",
        "stem = lambda w: [ ps.stem(x) for x in w ]\n",
        "\n",
        "print('remove_non_alphabets')\n",
        "data['text_of_comment'] = data['text_of_comment'].apply(remove_non_alphabets)\n",
        "\n",
        "print('tokenize')\n",
        "data['text_of_comment'] = data['text_of_comment'].apply(tokenize) # [ word_tokenize(row) for row in data['email']]\n",
        "\n",
        "print('stem')\n",
        "data['text_of_comment'] = data['text_of_comment'].apply(stem)\n",
        "\n",
        "print('Lemmatize')\n",
        "c = 0\n",
        "for words_list in data['text_of_comment']:\n",
        "    words_list = Lemmatize(words_list)\n",
        "    print(c)\n",
        "    c+=1\n",
        "\n",
        "print('complete')\n",
        "data['text_of_comment'] = data['text_of_comment'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "print(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASv3LNcIlAi6"
      },
      "source": [
        "Произвести разделение загруженного набора данных на обучающую, тестовую и валидационую выборки (в соотношении 80:10:10). Проверить, что сформированные выборки сбалансированы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frac_seed = random.randint(0,10)\n",
        "train_df = data.sample(frac=0.9, random_state=frac_seed, ignore_index=True)\n",
        "valid_df = data.sample(frac=0.1, random_state=frac_seed, ignore_index=True)\n",
        "for item in valid_df[\"text_of_comment\"]:\n",
        "    while item in train_df['text_of_comment']: \n",
        "        tmp = data.sample()\n",
        "        item[\"text_of_comment\"] = tmp['text_of_comment']\n",
        "        item[\"mark\"] = tmp[\"mark\"]\n",
        "    \n",
        "print(data)\n",
        "print(train_df)\n",
        "print(valid_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h639ECI4S6Lw"
      },
      "source": [
        "Написать модель нейронной сети для решения задачи классификации.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE9gsN9Y7N4q"
      },
      "outputs": [],
      "source": [
        "max_words = 10000\n",
        "stopWords = stopwords.words('russian')\n",
        "\n",
        "cv = CountVectorizer(max_features=max_words , stop_words=stopWords)\n",
        "\n",
        "sparse_matrix = cv.fit_transform(train_df[\"text_of_comment\"]).toarray()\n",
        "valid_sparse_matrix = cv.fit_transform(valid_df[\"text_of_comment\"]).toarray()\n",
        "print(sparse_matrix.shape)\n",
        "\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    valid_sparse_matrix, np.array(valid_df[\"mark\"])\n",
        ")\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    sparse_matrix, np.array(train_df[\"mark\"],test_size = 0.1, train_size= 0.9)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou1GmhpE7qKB"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear1 = nn.Linear(10000, 100)\n",
        "        self.linear2 = nn.Linear(100, 10)\n",
        "        self.linear3 = nn.Linear(10, 6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "#model = LogisticRegression()\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "x_train = torch.Tensor(x_train).float()\n",
        "y_train = [int(i) for i in y_train]\n",
        "y_train = torch.Tensor(y_train).long()\n",
        "x_val = torch.Tensor(x_val).float()\n",
        "y_val = [int(i) for i in y_val]\n",
        "y_val = torch.Tensor(y_val).long()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSpGptaOSwV_"
      },
      "source": [
        "Написать train loop (цикл обучения). Провести эксперименты по обучению с различными значениями параметров learning rate (скорость обучения) и ba tch size (размер мини-пакета). Выбрать по 3 значения для learning rate и batch size (итоговое количество экспериментов будет 9).\n",
        "\n",
        "Для каждого проведенного эксперимента вывести графики для значения функции потерь (ось x - итерация обучения/номер эпохи; ось y - значение функции потерь) и выбранной метрики качества (ось x - итерация обучения/номер эпохи; ось y - значение метрики качества). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def expirement(lr, batch_size):\n",
        "    model = LogisticRegression()\n",
        "    criterion = nn.BCELoss()\n",
        "    \n",
        "    data = torch.utils.data.DataLoader(x_train, batch_size = batch_size)\n",
        "    optimizer = torch.optim.Adam(params=model.parameters() , lr = lr)\n",
        "    epochs = 10\n",
        "    model.train()\n",
        "    loss_values = []\n",
        "    for epoch in range(epochs):\n",
        "        for elems in data: \n",
        "            #optimizer.zero_grad()\n",
        "            y_pred = model(x_train)\n",
        "            print(y_pred[batch_size], y_train[batch_size].resize(1).to(dtype=float))\n",
        "            loss = criterion(y_pred, y_train)\n",
        "            loss_values.append(loss.item())\n",
        "            pred = torch.max(y_pred, 1)[1].eq(y_train).sum()\n",
        "            acc = pred * 100.0 / len(x_train)\n",
        "            print('Epoch: {}, Loss: {}, Accuracy: {}%'.format(epoch+1, loss.item(), acc.numpy()))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    plt.plot(loss_values)\n",
        "    plt.title('Таблица эпох и потерь при lr='+str(lr) +\" batch_size=\"+str(batch_size))\n",
        "    plt.xlabel('Эпоха')\n",
        "    plt.ylabel('Потери')\n",
        "    plt.legend(['Потери'])\n",
        "    plt.show()\n",
        "    \n",
        "if True:\n",
        "    \n",
        "    lr_list=[0.0001,0.0002,0.0003]\n",
        "    batch_size=[1000,500,100]\n",
        "\n",
        "    for LR in lr_list:\n",
        "            for BZ in batch_size:\n",
        "                expirement(LR,BZ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5krZJ_nTTTWK"
      },
      "source": [
        "Оценить качество работы модели на тестовой выборке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hknojMesqbwT",
        "outputId": "60e1f68e-0b65-44ea-e437-299c64d56a69"
      },
      "outputs": [],
      "source": [
        "x_test = torch.Tensor(x_test).float()\n",
        "y_test = [int(i) for i in y_test]\n",
        "y_test = torch.Tensor(y_test).long()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i in range(20):\n",
        "        y_pred = model(x_test)\n",
        "        loss = criterion(y_pred, y_test)\n",
        "        pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n",
        "    print(\"Accuracy : {}%\".format(100 * pred / len(x_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDDDrsYrUyWh"
      },
      "source": [
        "Сделайте выводы по полученным результатам проведенных экспериментов. Какую модель из всех полученных стоит использовать?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrbhBk0vXZOx"
      },
      "outputs": [],
      "source": [
        "LR = 0.01\n",
        "BZ = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dgDk_ikZOcN"
      },
      "source": [
        "Сохранить обученную модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZW0J_RZjZPu1"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), os.path.join(\"/content/\", \"weight.pt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpFVxP8IZqB_"
      },
      "source": [
        "Выполните повторную инициализацию модели и загрузку весов. Продемонстрируйте работоспособность модели (пропустите через нее какой-то отзыв/рецензию и выведите результат)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFfYx7CPZqwO",
        "outputId": "80076e7a-9d02-4945-bcc1-c030fe295c6d"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(os.path.join(\"/content/\", \"weight.pt\")))\n",
        "data = torch.utils.data.DataLoader(x_test, batch_size=BZ, shuffle=True)\n",
        "model.eval()\n",
        "text_list = []\n",
        "with torch.no_grad():\n",
        "    for i in range(20):\n",
        "        y_pred = model(x_test)\n",
        "        loss = criterion(y_pred, y_test)\n",
        "        pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n",
        "    print(\"Accuracy : {}%\".format(100 * pred / len(x_test)))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNMS0xnbM8rZhMivC7AWvfp",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
